{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1935f9d-02db-468c-ade3-87f164b6d4f6",
   "metadata": {},
   "source": [
    "# Pagerank on subgraphs—efficient Monte-Carlo estimation\n",
    "\n",
    "In this repo you can find the reference code for my novel Subrank algorithm for efficiently computing the Pagerank distribution over $S$ subgraph of $G$.\n",
    "For the reasoning behind the algorithm, the definition and the analysis, I invite the interested reader to [read the paper](https://pippellia.com/pippellia/Social+Graph/Pagerank+on+subgraphs%E2%80%94efficient+Monte-Carlo+estimation).\n",
    "\n",
    "To play with it, follow these steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce6ba6-2539-4bd3-85c8-608eb83bfeb3",
   "metadata": {},
   "source": [
    "## Step 0: execute the necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4be85cb-c209-4fd8-b9ea-245607273fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "def load_network(name):\n",
    "\n",
    "    '''\n",
    "    This function loads the network graph and index map from storage.\n",
    "\n",
    "    INPUTS\n",
    "    ------\n",
    "    name: str\n",
    "        the name of the files, usually a timestamp like '1714823396'\n",
    "\n",
    "    OUTPUTS:\n",
    "    -------\n",
    "    index_map: dict\n",
    "        The dictionary {pk: node} that maps each public key to its corrispondent node id in the graph\n",
    "\n",
    "    network_graph: graph\n",
    "        A Networkx graph.\n",
    "    '''\n",
    "\n",
    "    if type(name) != str:\n",
    "        name = str(name)\n",
    "\n",
    "    # loading the index_map\n",
    "    with open('index_map_' + name + '.json', 'r') as f:\n",
    "        index_map = json.load(f)\n",
    "    \n",
    "    # loading the JSON for the graph\n",
    "    with open('network_graph_' + name + '.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # convert JSON back to graph\n",
    "    network_graph = nx.node_link_graph(data)\n",
    "\n",
    "    return index_map, network_graph\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "def get_mc_pagerank(G, R, nodelist = None, alpha=0.85):\n",
    "    \n",
    "    '''\n",
    "        Monte-Carlo complete path stopping at dandling nodes\n",
    "    \n",
    "        INPUTS\n",
    "        ------\n",
    "        G: graph\n",
    "            A directed Networkx graph. This function cannot work on directed graphs.\n",
    "            \n",
    "        R: int\n",
    "            The number of random walks to be performed per node\n",
    "            \n",
    "        nodelist: list, optional\n",
    "            the list of nodes in G networkx graph. \n",
    "            It is used to order the nodes in a specified way\n",
    "            \n",
    "        alpha: float, optional\n",
    "            It is the dampening factor of Pagerank. default value is 0.85\n",
    "\n",
    "        OUTPUTS\n",
    "        -------\n",
    "        walk_visited_count: CSR matrix\n",
    "            a Compressed Sparse Row (CSR) matrix; element (i,j) is equal to \n",
    "            the number of times v_j has been visited by a random walk started from v_i\n",
    "            \n",
    "        mc_pagerank: dict\n",
    "            The dictionary {node: pg} of the pagerank value for each node in G\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] K.Avrachenkov, N. Litvak, D. Nemirovsky, N. Osipova\n",
    "        \"Monte Carlo methods in PageRank computation: When one iteration is sufficient\"\n",
    "        https://www-sop.inria.fr/members/Konstantin.Avratchenkov/pubs/mc.pdf\n",
    "    '''\n",
    "\n",
    "    # validate all the inputs and initialize variables\n",
    "    N, nodelist, inverse_nodelist = _validate_inputs_and_init_mc(G, R, nodelist, alpha)\n",
    "\n",
    "    # initialize walk_visited_count as a sparse LIL matrix\n",
    "    walk_visited_count = lil_matrix((N, N), dtype='int')\n",
    "\n",
    "    progress_count = 0\n",
    "\n",
    "    # perform R random walks for each node\n",
    "    for node in nodelist:\n",
    "\n",
    "        # print progress every 200 nodes\n",
    "        progress_count += 1\n",
    "        if progress_count % 200 == 0:\n",
    "            print('progress = {:.2f}%'.format(100 * progress_count / N), end='\\r')\n",
    "        \n",
    "        for _ in range(R):\n",
    "\n",
    "            node_pos = inverse_nodelist[node]\n",
    "            walk_visited_count[node_pos, node_pos] += 1\n",
    "\n",
    "            current_node = node\n",
    "\n",
    "            while random.uniform(0,1) < alpha:\n",
    "                \n",
    "                successors = list(G.successors(current_node))\n",
    "                if not successors:\n",
    "                    break\n",
    "                    \n",
    "                current_node = random.choice(successors)\n",
    "                current_node_pos = inverse_nodelist[current_node]\n",
    "\n",
    "                # add current node to the walk_visited_count\n",
    "                walk_visited_count[node_pos, current_node_pos] += 1\n",
    "\n",
    "    # convert lil_matrix to csr_matrix for efficient storage and access\n",
    "    walk_visited_count = walk_visited_count.tocsr()\n",
    "\n",
    "    # sum all visits for each node into a numpy array\n",
    "    total_visited_count = np.array(walk_visited_count.sum(axis=0)).flatten()\n",
    "\n",
    "    # reciprocal of the number of total visits\n",
    "    one_over_s = 1 / sum(total_visited_count)\n",
    "    \n",
    "    mc_pagerank = {nodelist[j]: total_visited_count[j] * one_over_s for j in range(N)}\n",
    "\n",
    "    print('progress = 100%       ', end='\\r')\n",
    "    print('\\nTotal walks performed: ', N * R )\n",
    "    \n",
    "    return walk_visited_count, mc_pagerank\n",
    "\n",
    "\n",
    "def _validate_inputs_and_init_mc(G, R, nodelist, alpha):\n",
    "\n",
    "    '''\n",
    "    This function validate the inputs and initialize the following variables:\n",
    "    \n",
    "    N: int\n",
    "        the number of nodes in G Networkx graph\n",
    "\n",
    "    nodelist : list\n",
    "        the list of nodes in G Networkx graph\n",
    "\n",
    "    inverse_nodelist : dict\n",
    "       a dictionary that maps each node in G to its position in nodelist\n",
    "    '''\n",
    "\n",
    "    N = len(G)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"Graph G is empty\")\n",
    "    \n",
    "    if not isinstance(R, int) or R <= 0:\n",
    "        raise ValueError(\"R must be a positive integer\")\n",
    "    \n",
    "    if not isinstance(alpha, float) or not (0 < alpha < 1):\n",
    "        raise ValueError(\"alpha must be a float between 0 and 1\")\n",
    "    \n",
    "    if nodelist is not None and set(nodelist) != set(G.nodes()):\n",
    "        raise ValueError(\"nodelist does not match the nodes in G\")\n",
    "\n",
    "    elif nodelist is None:\n",
    "        nodelist = list(G.nodes())\n",
    "\n",
    "    # compute the inverse map of nodelist\n",
    "    inverse_nodelist = {nodelist[j]: j for j in range(N)}\n",
    "\n",
    "    return N, nodelist, inverse_nodelist\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.sparse import isspmatrix_csr\n",
    "import random\n",
    "\n",
    "def get_subrank(S, G, walk_visited_count, nodelist, alpha = 0.85):\n",
    "\n",
    "    '''\n",
    "        Subrank algorithm (stopping at dandling nodes);\n",
    "        it aims to approximate the Pagerank over S subgraph of G\n",
    "    \n",
    "        INPUTS\n",
    "        ------\n",
    "        S: graph\n",
    "            A directed Networkx graph, induced subgraph of G\n",
    "            \n",
    "        G: graph\n",
    "            A directed Networkx graph. This function cannot work on directed graphs.\n",
    "            \n",
    "        walk_visited_count: CSR matrix\n",
    "            a Compressed Sparse Row (CSR) matrix; element (i,j) is equal to \n",
    "            the number of times v_j has been visited by a random walk started from v_i\n",
    "\n",
    "        nodelist: list, optional\n",
    "            the list of nodes in G Networkx graph. It is used to decode walk_visited_count\n",
    "        \n",
    "       alpha: float, optional\n",
    "            It is the dampening factor of Pagerank. default value is 0.85\n",
    "\n",
    "        OUTPUTS\n",
    "        -------\n",
    "        subrank: dict\n",
    "            The dictionary {node: pg} of the pagerank value for each node in S\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        [1] Pippellia,\n",
    "        \"Pagerank on subgraphs—efficient Monte-Carlo estimation\"\n",
    "        https://pippellia.com/pippellia/Social+Graph/Pagerank+on+subgraphs%E2%80%94efficient+Monte-Carlo+estimation\n",
    "    '''\n",
    "    \n",
    "    # validate inputs and initialize variables\n",
    "    N, S_nodes, G_nodes, inverse_nodelist = _validate_inputs_and_init(S, G, walk_visited_count, nodelist, alpha)\n",
    "\n",
    "    # compute visited count from walks that started from S\n",
    "    visited_count_from_S = _get_visited_count_from_S(N, S_nodes, walk_visited_count, nodelist, inverse_nodelist)\n",
    "\n",
    "    # compute positive and negative walks to do\n",
    "    positive_walks, negative_walks = _get_walks_to_do(S_nodes, G_nodes, S, G, visited_count_from_S, alpha)\n",
    "\n",
    "    print(f'walks performed = {sum(positive_walks.values()) + sum(negative_walks.values())}')\n",
    "\n",
    "    # perform the walks and get the visited counts\n",
    "    positive_count = _perform_walks(S_nodes, S, positive_walks, alpha)\n",
    "    negative_count = _perform_walks(S_nodes, S, negative_walks, alpha)\n",
    "\n",
    "    # add the effects of the random walk to the count of G\n",
    "    new_visited_count = {node: visited_count_from_S[node] + positive_count[node] - negative_count[node]\n",
    "                        for node in S_nodes}\n",
    "\n",
    "    # compute the number of total visits\n",
    "    total_visits = sum(new_visited_count.values())\n",
    "\n",
    "    # compute the subrank\n",
    "    subrank = {node: visits / total_visits \n",
    "                   for node, visits in new_visited_count.items() }\n",
    "\n",
    "    return subrank\n",
    "\n",
    "def _validate_inputs_and_init(S, G, walk_visited_count, nodelist, alpha):\n",
    "\n",
    "    '''\n",
    "    This function validate the inputs and initialize the following variables:\n",
    "    \n",
    "    N: int\n",
    "        the number of nodes in G Networkx graph\n",
    "\n",
    "    S_nodes: set\n",
    "        the set of nodes that belongs to S\n",
    "\n",
    "    G_nodes: set\n",
    "        the set of nodes that belongs to G\n",
    "\n",
    "    inverse_nodelist : dict\n",
    "        a dictionary that maps each node in G to its position in nodelist\n",
    "        \n",
    "    Note: S being a subgraph of G is NOT checked because it's computationally expensive.\n",
    "    '''\n",
    "\n",
    "    if len(S) == 0:\n",
    "        raise ValueError(\"graph S is empty\")\n",
    "\n",
    "    N = len(G)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"graph G is empty\")\n",
    "    \n",
    "    if not isinstance(alpha, float) or not (0 < alpha < 1):\n",
    "        raise ValueError(\"alpha must be a float between 0 and 1\")\n",
    "\n",
    "    if not isspmatrix_csr(walk_visited_count) or walk_visited_count.shape != (N,N):\n",
    "        raise ValueError(f\"walk_visited_count must be a {(N,N)} CSR matrix\")\n",
    "\n",
    "    S_nodes = set(S.nodes())\n",
    "    G_nodes = set(G.nodes())\n",
    "    \n",
    "    if not nodelist or set(nodelist) != set(G_nodes):\n",
    "        raise ValueError(\"nodelist does not match the nodes in G\")\n",
    "\n",
    "    # compute the inverse map of nodelist\n",
    "    inverse_nodelist = {nodelist[j]: j for j in range(N)}\n",
    "\n",
    "    return N, S_nodes, G_nodes, inverse_nodelist\n",
    "\n",
    "\n",
    "def _get_visited_count_from_S(N, S_nodes, walk_visited_count, nodelist, inverse_nodelist):\n",
    "\n",
    "    '''\n",
    "    This function extracts the number of visits that come from walks that started from S\n",
    "    '''\n",
    "\n",
    "    # getting the indices of nodes in S\n",
    "    S_indices = [inverse_nodelist[node] for node in S_nodes]\n",
    "    \n",
    "    # Extract the rows\n",
    "    S_matrix = walk_visited_count[S_indices, :]\n",
    "\n",
    "    # Sum the rows\n",
    "    visited_count_from_S = np.array(S_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "    # convert to a dictionary\n",
    "    visited_count_from_S = {nodelist[j]: visited_count_from_S[j] for j in range(N)}\n",
    "    \n",
    "    return visited_count_from_S\n",
    "    \n",
    "\n",
    "def _get_walks_to_do(S_nodes, G_nodes, S, G, visited_count_from_S, alpha):\n",
    "\n",
    "    '''\n",
    "    This function calculates the positive and negative walks to be done for each node.\n",
    "    It is a necessary step to take into account the different structure of S\n",
    "    with respect to that of G.\n",
    "    '''\n",
    "\n",
    "    # compute nodes in G-S\n",
    "    external_nodes = G_nodes - S_nodes\n",
    "\n",
    "    # compute nodes in S that point to G-S\n",
    "    nodes_that_point_externally = {u for u,v in nx.edge_boundary(G, S_nodes, external_nodes)}\n",
    "\n",
    "    walks_to_do = {node: 0 for node in S_nodes}\n",
    "\n",
    "    # add positive random walks to walks_to_do\n",
    "    for node in nodes_that_point_externally:\n",
    "\n",
    "        successors = set(G.successors(node)) & S_nodes\n",
    "\n",
    "        if successors:\n",
    "\n",
    "            # compute estimate visits\n",
    "            visited_count = visited_count_from_S[node]\n",
    "            degree_S = S.out_degree(node)\n",
    "            degree_G = G.out_degree(node)\n",
    "            estimate_visits = alpha * visited_count * (1/degree_S - 1/degree_G)\n",
    "\n",
    "            for succ in successors:\n",
    "                walks_to_do[succ] += estimate_visits\n",
    "\n",
    "    # subtract number of negative random walks\n",
    "    for node in external_nodes:\n",
    "\n",
    "        successors = set(G.successors(node)) & S_nodes\n",
    "\n",
    "        if successors:\n",
    "            \n",
    "            # compute estimate visits\n",
    "            visited_count = visited_count_from_S[node]\n",
    "            degree = G.out_degree(node)\n",
    "            estimate_visits = alpha * visited_count / degree\n",
    "\n",
    "            for succ in successors:\n",
    "                walks_to_do[succ] -= estimate_visits\n",
    "\n",
    "    # split the walks to do into positive and negative\n",
    "    positive_walks_to_do = {node: round(value) for node,value in walks_to_do.items() if value > 0 }\n",
    "    negative_walks_to_do = {node: round(-value) for node,value in walks_to_do.items() if value < 0 }\n",
    "\n",
    "    return positive_walks_to_do, negative_walks_to_do\n",
    "    \n",
    "\n",
    "def _perform_walks(S_nodes, S, walks_to_do, alpha):\n",
    "\n",
    "    '''\n",
    "    This function performs a certain number of random walks on S for each node;\n",
    "    It then returns the visited count for each node in S.\n",
    "    '''\n",
    "\n",
    "    # initializing the visited count\n",
    "    visited_count = {node: 0 for node in S_nodes}\n",
    "\n",
    "    for starting_node in walks_to_do.keys():\n",
    "\n",
    "        num = walks_to_do[starting_node]\n",
    "\n",
    "        # performing num random walks\n",
    "        for _ in range(num):\n",
    "\n",
    "            current_node = starting_node\n",
    "            visited_count[current_node] += 1\n",
    "\n",
    "            # performing one random walk\n",
    "            while random.uniform(0,1) < alpha:\n",
    "    \n",
    "                successors = list(S.successors(current_node))\n",
    "        \n",
    "                if not successors:\n",
    "                    break\n",
    "    \n",
    "                current_node = random.choice(successors)\n",
    "\n",
    "                # updating the visited count\n",
    "                visited_count[current_node] += 1\n",
    "\n",
    "    return visited_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b3da4-39c0-4fb0-8687-f08aea70f25d",
   "metadata": {},
   "source": [
    "## Step 1: load the graph database\n",
    "\n",
    "First, you have to load the networkx graph database into memory by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a48d91-80e1-4016-8030-9ac9ef0ab1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the database...\n",
      "finished in 17.221821308135986 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# loading the database\n",
    "print('loading the database...')\n",
    "tic = time.time()\n",
    "\n",
    "index_map, G = load_network(1714823396)\n",
    "\n",
    "toc = time.time()\n",
    "print(f'finished in {toc-tic} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1dc28-5af4-4097-9987-103520588f81",
   "metadata": {},
   "source": [
    "## Step 2: Compute Pagerank over $G$\n",
    "\n",
    "Compute the pagerank over $G$ by using the networkx built-in pagerank function that uses the power iteration method.\n",
    "This vector will be considered as the real Pagerank vector and will be used to compute the errors of the Monte-Carlo algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5a4f83-d5b9-4def-a7f7-403cd0beedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing global pagerank...\n",
      "finished in 18.110231637954712 seconds\n"
     ]
    }
   ],
   "source": [
    "# computing the pagerank\n",
    "print('computing global pagerank...')\n",
    "tic = time.time()\n",
    "\n",
    "p_G = nx.pagerank(G, tol=1e-12)\n",
    "\n",
    "toc = time.time()\n",
    "print(f'finished in {toc-tic} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50552e62-d66d-4a02-b49f-33c299e8311b",
   "metadata": {},
   "source": [
    "## Step 3: Approximate Pagerank over $G$ using Monte-Carlo\n",
    "\n",
    "Compute the pagerank over $G$ using a simple Monte-Carlo implementation and compute the L1 error.\n",
    "This step is essential because it returns the csr-matrix `walk_visited_count`, that will be used later by the Subrank algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bbe6d2-c19a-4a84-8ba0-13ae2b6e13d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 100%       \n",
      "Total walks performed:  1951740\n",
      "performed random walks in 35.56719255447388 seconds\n",
      "error pagerank vs mc pagerank in G = 0.05047368343396303\n"
     ]
    }
   ],
   "source": [
    "# number of the random walks per node\n",
    "R = 10\n",
    "\n",
    "# fix the order of the nodes\n",
    "nodelist = list(G.nodes())\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# perform the random walks and get the monte-carlo pagerank\n",
    "walk_visited_count, mc_pagerank = get_mc_pagerank(G, R, nodelist)\n",
    "\n",
    "toc = time.time()\n",
    "print(f'performed random walks in {toc-tic} seconds')\n",
    "\n",
    "# computing the L1 error\n",
    "error_G_mc = sum( abs(p_G[node] - mc_pagerank[node])\n",
    "                  for node in G.nodes() )\n",
    "\n",
    "print(f'error pagerank vs mc pagerank in G = {error_G_mc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3bf52-7841-4842-a3f2-6f6d066e0c94",
   "metadata": {},
   "source": [
    "## Step 4: Select random subgraph $S$ and compute its Pagerank distribution\n",
    "\n",
    "Select a random subgraph $S$ consisting of 50k nodes, and compute its Pagerank distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00c005e-2064-4975-acb6-3bcf52eb8594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing local pagerank...\n",
      "finished in 2.2579879760742188 seconds\n"
     ]
    }
   ],
   "source": [
    "# selecting random subgraph S\n",
    "S_nodes = set(random.sample(list(G.nodes()), k=50000))\n",
    "S = G.subgraph(S_nodes).copy()\n",
    "\n",
    "# computing pagerank over S\n",
    "print('computing local pagerank...')\n",
    "tic = time.time()\n",
    "\n",
    "p_S = nx.pagerank(S, tol=1e-12)\n",
    "\n",
    "toc = time.time()\n",
    "print(f'finished in {toc-tic} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0ae95-87c1-4f5d-890f-42ff5892d881",
   "metadata": {},
   "source": [
    "## Step 5: Approximate Pagerank over $S$ using Subrank\n",
    "\n",
    "Run the Subrank algorithm to approximate the Pagerank over $S$ subgraph of $G$. Then compute the L1 error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41637e2b-1998-43ff-9811-a7bbe658d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing subrank over S...\n",
      "walks performed = 162010\n",
      "performed random walks in 2.6661059856414795 seconds\n",
      "error pagerank vs subrank in S = 0.05139446533060389\n"
     ]
    }
   ],
   "source": [
    "# computing subrank\n",
    "print('computing subrank over S...')\n",
    "tic = time.time()\n",
    "\n",
    "subrank = get_subrank(S, G, walk_visited_count, nodelist)\n",
    "\n",
    "toc = time.time()\n",
    "print(f'performed random walks in {toc-tic} seconds')\n",
    "\n",
    "# computing the L1 error\n",
    "error_S_subrank = sum( abs(p_S[node] - subrank[node])\n",
    "                      for node in S_nodes )\n",
    "\n",
    "print(f'error pagerank vs subrank in S = {error_S_subrank}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929d6dc-37ef-4a4a-bc9c-c37bdafd012a",
   "metadata": {},
   "source": [
    "## Step 6: Approximate Pagerank over $S$ using Monte-Carlo naive recomputation\n",
    "\n",
    "Run the Monte-Carlo Pagerank algorithm on $S$ as a reference for the number of random walks required and the error achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14907960-116b-405d-9f73-85e625958050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing naive monte-carlo pagerank over S\n",
      "progress = 100%       \n",
      "Total walks performed:  500000\n",
      "finished in 4.987701177597046 seconds\n",
      "error pagerank vs mc pagerank in S = 0.04875892632550595\n"
     ]
    }
   ],
   "source": [
    "# computing the monte-carlo pagerank \n",
    "print('computing naive monte-carlo pagerank over S')\n",
    "tic = time.time()\n",
    "\n",
    "_, mc_pagerank_S_naive = get_mc_pagerank(S,R)\n",
    "\n",
    "toc = time.time()\n",
    "print(f'finished in {toc-tic} seconds')\n",
    "\n",
    "# computing the L1 error\n",
    "error_S_naive = sum( abs(p_S[node] - mc_pagerank_S_naive[node])\n",
    "                      for node in S.nodes())\n",
    "\n",
    "print(f'error pagerank vs mc pagerank in S = {error_S_naive}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
